{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/shared/TORCS_test.tfrecords'\n",
    "\n",
    "feature = {'fast': tf.FixedLenFeature([], tf.float32),\n",
    "    'dist_RR': tf.FixedLenFeature([], tf.float32),\n",
    "    'dist_MM': tf.FixedLenFeature([], tf.float32),\n",
    "    'dist_LL': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_RR': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_MR': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_ML': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_LL': tf.FixedLenFeature([], tf.float32),\n",
    "    'dist_R': tf.FixedLenFeature([], tf.float32),\n",
    "    'dist_L': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_R': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_M': tf.FixedLenFeature([], tf.float32),\n",
    "    'toMarking_L': tf.FixedLenFeature([], tf.float32),\n",
    "    'angle': tf.FixedLenFeature([], tf.float32),\n",
    "    'image': tf.FixedLenFeature([], tf.string)}\n",
    "\n",
    "# Create a list of filenames and pass it to a queue\n",
    "filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "# Define a reader and read the next record\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "# Decode the record read by the reader\n",
    "features = tf.parse_single_example(serialized_example, features=feature)\n",
    "# Convert the image data from string back to the numbers\n",
    "image = tf.decode_raw(features['image'], tf.uint8)\n",
    "\n",
    "# Cast label data into float32\n",
    "fast = tf.cast(features['fast'], tf.float32)\n",
    "\n",
    "# rescale all targets to [0,1], numbers were taken from source code of DeepDriving\n",
    "dist_RR = tf.cast(features['dist_RR'], tf.float32) / 95.0 + 0.12\n",
    "dist_MM = tf.cast(features['dist_MM'], tf.float32) / 95.0 + 0.12\n",
    "dist_LL = tf.cast(features['dist_LL'], tf.float32) / 95.0 + 0.12\n",
    "\n",
    "toMarking_RR = tf.cast(features['toMarking_RR'], tf.float32) / 6.8752 - 0.48181\n",
    "toMarking_MR = tf.cast(features['toMarking_MR'], tf.float32) / 6.25 + 0.02\n",
    "toMarking_ML = tf.cast(features['toMarking_ML'], tf.float32) / 6.25 + 0.98\n",
    "toMarking_LL = tf.cast(features['toMarking_LL'], tf.float32) / 6.8752 + 1.48181\n",
    "\n",
    "dist_R = tf.cast(features['dist_R'], tf.float32) / 95.0 + 0.12\n",
    "dist_L = tf.cast(features['dist_L'], tf.float32) / 95.0 + 0.12\n",
    "\n",
    "toMarking_R = tf.cast(features['toMarking_R'], tf.float32) / 5.6249 - 0.34445\n",
    "toMarking_M = tf.cast(features['toMarking_M'], tf.float32) / 6.8752 + 0.39091\n",
    "toMarking_L = tf.cast(features['toMarking_L'], tf.float32) / 5.6249 + 1.34445\n",
    "\n",
    "angle = tf.cast(features['angle'], tf.float32) / 1.1 + 0.5\n",
    "\n",
    "# Reshape image data into the original shape\n",
    "image = tf.reshape(image, [210, 280, 3])\n",
    "\n",
    "# rescale from [0..255] to [-1..1]\n",
    "image = tf.cast(image, tf.float32)\n",
    "image = (image - 128.0) / 128.0\n",
    "\n",
    "# Creates batches by randomly shuffling tensors\n",
    "#images=1\n",
    "images, fasts, dist_RRs, dist_MMs, dist_LLs, toMarking_RRs, toMarking_MRs, toMarking_MLs, toMarking_LLs, dist_Rs, dist_Ls, toMarking_Rs, toMarking_Ms, toMarking_Ls, angles = tf.train.shuffle_batch(\n",
    "                    [image, fast, dist_RR, dist_MM, dist_LL, toMarking_RR, toMarking_MR, toMarking_ML,\n",
    "                        toMarking_LL, dist_R, dist_L, toMarking_R, toMarking_M, toMarking_L, angle],\n",
    "                        batch_size=16, capacity=30, num_threads=1, min_after_dequeue=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.concat([tf.expand_dims(fasts,1), tf.expand_dims(dist_RRs,1), tf.expand_dims(dist_MMs,1), tf.expand_dims(dist_LLs,1), \n",
    "                    tf.expand_dims(toMarking_RRs,1), tf.expand_dims(toMarking_MRs,1), tf.expand_dims(toMarking_MLs,1),\n",
    "                    tf.expand_dims(toMarking_LLs,1), tf.expand_dims(dist_Rs,1), tf.expand_dims(dist_Ls,1), tf.expand_dims(toMarking_Rs,1),\n",
    "                    tf.expand_dims(toMarking_Ms,1), tf.expand_dims(toMarking_Ls,1), tf.expand_dims(angles,1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from alexnet import alexnet_v2\n",
    "\n",
    "\n",
    "logits, endpoints = alexnet_v2(images,\n",
    "               num_classes=1000,\n",
    "               is_training=True,\n",
    "               dropout_keep_prob=0.999,\n",
    "               spatial_squeeze=True,\n",
    "               scope='alexnet_v2')\n",
    "\n",
    "y_pred = endpoints['alexnet_v2/fc8']\n",
    "loss = tf.reduce_mean(tf.squared_difference(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from mobilenet_v1 import mobilenet_v1\n",
    "\n",
    "# logits, endpoints = mobilenet_v1(images, #tf.cast(images, tf.float32),\n",
    "#                  num_classes=1000,\n",
    "#                  dropout_keep_prob=0.999,\n",
    "#                  is_training=True,\n",
    "#                  min_depth=8,\n",
    "#                  depth_multiplier=0.75,\n",
    "#                  conv_defs=None,\n",
    "#                  prediction_fn=tf.contrib.layers.softmax,\n",
    "#                  spatial_squeeze=True,\n",
    "#                  reuse=None,\n",
    "#                  scope='MobilenetV1')\n",
    "\n",
    "# y_pred = endpoints['Logits']\n",
    "# loss = tf.reduce_mean(tf.squared_difference(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model_alex/139999.ckpt\n"
     ]
    }
   ],
   "source": [
    "angle_residuals = []\n",
    "\n",
    "toMarking_L_residuals = []\n",
    "toMarking_M_residuals = []\n",
    "toMarking_R_residuals = []\n",
    "\n",
    "dist_L_residuals = []\n",
    "dist_R_residuals = []\n",
    "\n",
    "toMarking_LL_residuals = []\n",
    "toMarking_ML_residuals = []\n",
    "toMarking_MR_residuals = []\n",
    "toMarking_RR_residuals = []\n",
    "\n",
    "dist_LL_residuals = []\n",
    "dist_MM_residuals = []\n",
    "dist_RR_residuals = []\n",
    "\n",
    "angles = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # restore model\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    saver.restore(sess, 'model_alex/139999.ckpt')\n",
    "    \n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for batch_index in range(2533/16):\n",
    "        p, y = sess.run([y_pred, y_true])\n",
    "        for j in range(y_true.shape[0]):\n",
    "            residuals = p[j,:] - y[j,:]\n",
    "            \n",
    "            angles.append(y[j,13])\n",
    "            angle_residuals.append(residuals[13-0] * 1.1)\n",
    "\n",
    "            toMarking_L_residuals.append(residuals[13-1]*5.6249)\n",
    "            toMarking_M_residuals.append(residuals[13-2]*6.8752)\n",
    "            toMarking_R_residuals.append(residuals[13-3]*5.6249)\n",
    "\n",
    "            dist_L_residuals.append(residuals[13-4]*95)\n",
    "            dist_R_residuals.append(residuals[13-5]*95)\n",
    "\n",
    "            toMarking_LL_residuals.append(residuals[13-6] * 6.8752)\n",
    "            toMarking_ML_residuals.append(residuals[13-7] * 6.25)\n",
    "            toMarking_MR_residuals.append(residuals[13-8] * 6.25)\n",
    "            toMarking_RR_residuals.append(residuals[13-9] * 6.8752)\n",
    "\n",
    "            dist_LL_residuals.append(residuals[13-10] * 95)\n",
    "            dist_MM_residuals.append(residuals[13-11] * 95)\n",
    "            dist_RR_residuals.append(residuals[13-12] * 95)\n",
    "\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet 140k iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle: 0.0401853007634, to_LL: 0.172279581355, to_ML: 0.236961272449, to_MR: 0.219013178802, to_RR: 0.233891143186, to_L: 0.168281958686, to_M: 0.254165021174, to_R: 0.206914217719\n"
     ]
    }
   ],
   "source": [
    "print(\"angle: {}, to_LL: {}, to_ML: {}, to_MR: {}, to_RR: {}, to_L: {}, to_M: {}, to_R: {}\".format(\n",
    "    np.mean(np.abs(angle_residuals)), np.mean(np.abs(toMarking_LL_residuals)), np.mean(np.abs(toMarking_ML_residuals)),\n",
    "    np.mean(np.abs(toMarking_MR_residuals)), np.mean(np.abs(toMarking_RR_residuals)), np.mean(np.abs(toMarking_L_residuals)),\n",
    "    np.mean(np.abs(toMarking_M_residuals)), np.mean(np.abs(toMarking_R_residuals))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_L: 1.629121691, dist_R: 1.79990233818, dist_LL: 1.89498640785, dist_MM: 2.10143216414, dist_RR: 2.34845774295\n"
     ]
    }
   ],
   "source": [
    "print(\"dist_L: {}, dist_R: {}, dist_LL: {}, dist_MM: {}, dist_RR: {}\".format(\n",
    "    np.mean(np.abs(dist_L_residuals)), np.mean(np.abs(dist_R_residuals)),\n",
    "    np.mean(np.abs(dist_LL_residuals)), np.mean(np.abs(dist_MM_residuals)), np.mean(np.abs(dist_RR_residuals))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet 80k iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle: 0.0416114217469, to_LL: 0.201853084625, to_ML: 0.236998392616, to_MR: 0.222831214793, to_RR: 0.239087398509, to_L: 0.175881728919, to_M: 0.273412398223, to_R: 0.247124108439\n"
     ]
    }
   ],
   "source": [
    "print(\"angle: {}, to_LL: {}, to_ML: {}, to_MR: {}, to_RR: {}, to_L: {}, to_M: {}, to_R: {}\".format(\n",
    "    np.mean(np.abs(angle_residuals)), np.mean(np.abs(toMarking_LL_residuals)), np.mean(np.abs(toMarking_ML_residuals)),\n",
    "    np.mean(np.abs(toMarking_MR_residuals)), np.mean(np.abs(toMarking_RR_residuals)), np.mean(np.abs(toMarking_L_residuals)),\n",
    "    np.mean(np.abs(toMarking_M_residuals)), np.mean(np.abs(toMarking_R_residuals))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"dist_L: {}, dist_R: {}, dist_LL: {}, dist_MM: {}, dist_RR: {}\".format(\n",
    "    np.mean(np.abs(dist_L_residuals)), np.mean(np.abs(dist_R_residuals)),\n",
    "    np.mean(np.abs(dist_LL_residuals)), np.mean(np.abs(dist_MM_residuals)), np.mean(np.abs(dist_RR_residuals))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenet 80k iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle: 0.0491310474121, to_LL: 0.354534974728, to_ML: 0.383371908602, to_MR: 0.350780200649, to_RR: 0.412539151577, to_L: 0.307434286895, to_M: 0.432408641085, to_R: 0.352634229591\n"
     ]
    }
   ],
   "source": [
    "print(\"angle: {}, to_LL: {}, to_ML: {}, to_MR: {}, to_RR: {}, to_L: {}, to_M: {}, to_R: {}\".format(\n",
    "    np.mean(np.abs(angle_residuals)), np.mean(np.abs(toMarking_LL_residuals)), np.mean(np.abs(toMarking_ML_residuals)),\n",
    "    np.mean(np.abs(toMarking_MR_residuals)), np.mean(np.abs(toMarking_RR_residuals)), np.mean(np.abs(toMarking_L_residuals)),\n",
    "    np.mean(np.abs(toMarking_M_residuals)), np.mean(np.abs(toMarking_R_residuals))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_L: 9.00189648471, dist_R: 10.0919151594, dist_LL: 11.0662903272, dist_MM: 18.9990643161, dist_RR: 10.2342460218\n"
     ]
    }
   ],
   "source": [
    "print(\"dist_L: {}, dist_R: {}, dist_LL: {}, dist_MM: {}, dist_RR: {}\".format(\n",
    "    np.mean(np.abs(dist_L_residuals)), np.mean(np.abs(dist_R_residuals)),\n",
    "    np.mean(np.abs(dist_LL_residuals)), np.mean(np.abs(dist_MM_residuals)), np.mean(np.abs(dist_RR_residuals))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
